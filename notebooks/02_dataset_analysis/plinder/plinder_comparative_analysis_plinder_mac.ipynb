{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from posebusters.posebusters import PoseBusters\n",
    "from rdkit import Chem\n",
    "import os\n",
    "import pandas as pd\n",
    "import re \n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and processing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### custom approaches to add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Approach import DiffDockApproach, DiffDockPocketApproach, GninaApproach, SurfDockApproach, ICMApproach, ChaiApproach\n",
    "exp_name = \"plinder_set_0\"\n",
    "approaches = [\n",
    "    DiffDockApproach(),\n",
    "    DiffDockPocketApproach(),\n",
    "    GninaApproach(),\n",
    "    SurfDockApproach(),\n",
    "    ICMApproach(),\n",
    "    ChaiApproach(),\n",
    "]\n",
    "df_all = []\n",
    "for approach in approaches:\n",
    "    method_name = approach.get_name()\n",
    "    print(method_name)\n",
    "    df_method  = pd.read_csv(f\"{method_name}_{exp_name}_results.csv\")\n",
    "    print(df_method.shape)\n",
    "    df_all.append(df_method)\n",
    "\n",
    "df_combined = pd.concat(df_all, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_combined[df_combined.method == 'surfdock']['protein'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Analysis\n",
    "\n",
    "### Basic sumaries and Distributions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['rmsd_≤_1å'] = df_combined['rmsd'] <=1 \n",
    "df_combined['rmsd_≤_5å'] = df_combined['rmsd'] <=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined[\"method\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined[(df_combined['method'] == 'vina') ].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get proteins present in ICM method\n",
    "icm_proteins = df_combined[df_combined['method'] == 'icm']['protein'].unique()\n",
    "# Filter vina data to keep only proteins that exist in ICM\n",
    "df_combined_filtered = df_combined[\n",
    "      (df_combined['protein'].isin(icm_proteins))]\n",
    "\n",
    "\n",
    "# # Filter gnina data to keep only proteins that exist in ICM\n",
    "# df_combined_filtered = df_combined[\n",
    "#     ~((df_combined['method'] == 'gnina') & \n",
    "#       (~df_combined['protein'].isin(icm_proteins)))\n",
    "# ]\n",
    "\n",
    "# df_combined = df_combined_filtered\n",
    "# print(df_combined['method'].value_counts())\n",
    "\n",
    "# # Filter vina data to keep only proteins that exist in ICM\n",
    "# df_combined_filtered = df_combined[\n",
    "#     ~((df_combined['method'] == 'vina') & \n",
    "#       (~df_combined['protein'].isin(icm_proteins)))\n",
    "# ]\n",
    "\n",
    "# # Filter vina data to keep only proteins that exist in ICM\n",
    "# df_combined_filtered = df_combined[\n",
    "#     ~((df_combined['method'] == 'surfdock') & \n",
    "#       (~df_combined['protein'].isin(icm_proteins)))\n",
    "# ]\n",
    "\n",
    "\n",
    "df_combined = df_combined_filtered\n",
    "print(df_combined['method'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.groupby(\"method\")['method'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.groupby(\"method\")[\"rmsd_≤_2å\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.groupby(\"method\")[\"rmsd_≤_2å\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.groupby(\"method\")[\"rmsd\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv(f\"{exp_name}_results_filtered.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top-1 overlapped proteins with diffdock**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_proteins = df_combined.loc[df_combined[\"method\"] == \"diffdock\", \"protein\"].unique()\n",
    "df_icm_for_same_proteins = df_combined.loc[\n",
    "    (df_combined[\"method\"] == \"icm\") &\n",
    "    (df_combined[\"protein\"].isin(common_proteins))\n",
    "]\n",
    "df_icm_for_same_proteins['rmsd_≤_2å'].value_counts()\n",
    "df_icm_for_same_proteins_top1 = df_icm_for_same_proteins.loc[\n",
    "    df_icm_for_same_proteins.groupby(\"protein\")[\"score\"].idxmin()\n",
    "]\n",
    "df_icm_for_same_proteins_top1['rmsd_≤_2å'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms and densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=df_combined, x=\"rmsd\", hue=\"method\", shade=True)\n",
    "plt.title(\"RMSD KDE by method\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### absolute number of successful predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined[\"success\"] = df_combined[\"rmsd_≤_2å\"]\n",
    "# For each protein, count how many methods succeeded\n",
    "success_counts = (\n",
    "    df_combined[df_combined[\"success\"] == True]\n",
    "    .groupby([\"protein\",\"method\"])[\"success\"]\n",
    "    .first()  # or .any(), if multiple rows\n",
    "    .unstack(fill_value=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For method=\"icm\"\n",
    "print(\"\\nAbsolute successes per method:\")\n",
    "for method in df_combined[\"method\"].unique():\n",
    "    method_df = df_combined[df_combined[\"method\"] == method]\n",
    "    method_success_count = success_counts[method].sum()  # Count True values\n",
    "    total_proteins = method_df[\"protein\"].nunique()  # Count unique proteins\n",
    "    print(f\"{method}: {method_success_count / total_proteins}.2f, {method_success_count} successes out of {total_proteins} proteins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Histogram for 1å, 2å, and 5å**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion of accurate poses\n",
    "melted = df_combined.melt(id_vars='method', \n",
    "                        value_vars=['rmsd_≤_1å', 'rmsd_≤_2å', 'rmsd_≤_5å'],\n",
    "                        var_name='RMSD_Group',\n",
    "                        value_name='Is_Accurate')\n",
    "\n",
    "prop = melted.groupby(['method', 'RMSD_Group'])['Is_Accurate'].mean().reset_index()\n",
    "\n",
    "sns.barplot(data=prop, x='method', y='Is_Accurate', hue='RMSD_Group')\n",
    "plt.ylabel('Proportion of Accurate Poses')\n",
    "plt.title('Proportion of Accurate Poses by Docking Approach')\n",
    "plt.legend(title='RMSD Group', labels=['RMSD < 1 Å', 'RMSD < 2 Å', 'RMSD < 5 Å'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create success columns for each RMSD threshold\n",
    "df_combined['success_1å'] = df_combined['rmsd_≤_1å']\n",
    "df_combined['success_2å'] = df_combined['rmsd_≤_2å']\n",
    "df_combined['success_5å'] = df_combined['rmsd_≤_5å']\n",
    "\n",
    "# Group by protein and method, and check if any conformer satisfies each threshold\n",
    "success_agg = df_combined.groupby(['protein', 'method']).agg({\n",
    "    'success_1å': 'max',\n",
    "    'success_2å': 'max',\n",
    "    'success_5å': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "# Melt the aggregated DataFrame for plotting\n",
    "melted_success = success_agg.melt(\n",
    "    id_vars=['protein', 'method'],\n",
    "    value_vars=['success_1å', 'success_2å', 'success_5å'],\n",
    "    var_name='RMSD_Group',\n",
    "    value_name='Is_Accurate'\n",
    ")\n",
    "\n",
    "# Calculate the proportion of accurate poses\n",
    "prop_success = melted_success.groupby(['method', 'RMSD_Group'])['Is_Accurate'].mean().reset_index()\n",
    "\n",
    "# Plot the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=prop_success, x='method', y='Is_Accurate', hue='RMSD_Group')\n",
    "plt.ylabel('Proportion of Accurate Poses')\n",
    "plt.title('Proportion of Accurate Poses by Docking Approach')\n",
    "plt.legend(title='RMSD Group', labels=['RMSD ≤ 1 Å', 'RMSD ≤ 2 Å', 'RMSD ≤ 5 Å'])\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create success columns for each RMSD threshold\n",
    "df_combined['success_1å'] = df_combined['rmsd_≤_1å']\n",
    "df_combined['success_2å'] = df_combined['rmsd_≤_2å']\n",
    "df_combined['success_5å'] = df_combined['rmsd_≤_5å']\n",
    "\n",
    "# Group by protein and method, and check if any conformer satisfies each threshold\n",
    "success_agg = df_combined.groupby(['protein', 'method']).agg({\n",
    "    'success_1å': 'max',\n",
    "    'success_2å': 'max',\n",
    "    'success_5å': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "# Melt the aggregated DataFrame for plotting\n",
    "melted_success = success_agg.melt(\n",
    "    id_vars=['protein', 'method'],\n",
    "    value_vars=['success_1å', 'success_2å', 'success_5å'],\n",
    "    var_name='RMSD_Group',\n",
    "    value_name='Is_Accurate'\n",
    ")\n",
    "\n",
    "# Calculate the proportion of accurate poses\n",
    "prop_success = melted_success.groupby(['method', 'RMSD_Group'])['Is_Accurate'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(\n",
    "    data=prop_success,\n",
    "    x='method',\n",
    "    y='Is_Accurate',\n",
    "    hue='RMSD_Group'\n",
    ")\n",
    "\n",
    "# annotate each bar with its height (proportion)\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(\n",
    "        p.get_x() + p.get_width() / 2.,\n",
    "        height + 0.01,\n",
    "        f\"{height:.2f}\",\n",
    "        ha='center',\n",
    "        va='bottom'\n",
    "    )\n",
    "\n",
    "plt.ylabel('Proportion of Accurate Poses')\n",
    "plt.title('Proportion of Accurate Poses by Docking Approach')\n",
    "plt.legend(\n",
    "    title='RMSD Group',\n",
    "    labels=['RMSD ≤ 1 Å', 'RMSD ≤ 2 Å', 'RMSD ≤ 5 Å']\n",
    ")\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0, 1.1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative Plots for the RMSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by method and example, and compute the minimum RMSD among the multiple conformations\n",
    "df_min_rmsd = (\n",
    "    df_combined\n",
    "    .groupby([\"method\", \"protein\"], as_index=False)[\"rmsd\"]\n",
    "    .min()\n",
    "    .rename(columns={\"rmsd\": \"min_rmsd\"})\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot the ECDF for min_rmsd by method, capturing the Axes object\n",
    "ax = sns.ecdfplot(\n",
    "    data=df_min_rmsd,\n",
    "    x=\"min_rmsd\",\n",
    "    hue=\"method\"\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Minimum RMSD (Å) per Example\")\n",
    "plt.xlim(0, 10)\n",
    "plt.ylabel(\"Proportion of Examples with RMSD ≤ x\")\n",
    "plt.title(\"Cumulative Distribution of Minimum RMSD by Method\")\n",
    "\n",
    "# Manually fetch the handles and labels from the Axes\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "# Then create the legend manually\n",
    "plt.legend(handles, labels, title=\"Method\", loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the unique docking methods\n",
    "methods = df_min_rmsd[\"method\"].unique()\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for m in methods:\n",
    "    # Filter the data for this method\n",
    "    subset = df_min_rmsd[df_min_rmsd[\"method\"] == m][\"min_rmsd\"].values\n",
    "    # Sort min_rmsd\n",
    "    sorted_vals = np.sort(subset)\n",
    "    # Compute the empirical CDF\n",
    "    yvals = np.arange(1, len(sorted_vals) + 1) / len(sorted_vals)\n",
    "    # Plot the curve\n",
    "    plt.plot(sorted_vals, yvals, label=m)\n",
    "\n",
    "plt.axvline(x=2, color='red', linestyle='--', label='2 Å threshold')\n",
    "plt.xlabel(\"Minimum RMSD (Å) per Example\")\n",
    "plt.xlim(0, 10)\n",
    "plt.ylabel(\"Proportion of Examples with RMSD <= x\")\n",
    "plt.title(\"Cumulative Distribution of Minimum RMSD by Method\")\n",
    "plt.legend(title=\"Method\", loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df_combined.dropna(subset=[\"score\"]), x=\"score\", hue=\"method\", kde=True)\n",
    "plt.title(\"Docking Score distributions by method\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ICM score range for scaling reference\n",
    "icm_min = df_combined[df_combined['method'] == 'icm']['score'].min()\n",
    "icm_max = df_combined[df_combined['method'] == 'icm']['score'].max()\n",
    "\n",
    "# Create normalized scores column\n",
    "def normalize_to_icm_scale(group):\n",
    "    method = group['method'].iloc[0]\n",
    "    if method == 'icm':\n",
    "        return group['score']\n",
    "    else:\n",
    "        # Min-max normalization scaled to ICM range\n",
    "        method_min = group['score'].min()\n",
    "        method_max = group['score'].max()\n",
    "        return (group['score'] - method_min) * (icm_max - icm_min) / (method_max - method_min) + icm_min\n",
    "\n",
    "# Apply normalization\n",
    "df_combined['normalized_score'] = df_combined.groupby('method').apply(normalize_to_icm_scale).reset_index(level=0, drop=True)\n",
    "\n",
    "# Plot comparison\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df_combined, x='method', y='normalized_score')\n",
    "plt.title('Normalized Scores Across Methods')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confidence/Score histograms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with subplots for each method\n",
    "methods = df_combined['method'].unique()\n",
    "n_methods = len(methods)\n",
    "fig, axes = plt.subplots(1, n_methods, figsize=(20, 4))\n",
    "\n",
    "for idx, method in enumerate(methods):\n",
    "    if method == 'chai-1':\n",
    "        continue\n",
    "    method_data = df_combined[df_combined['method'] == method].dropna(subset=['score'])\n",
    "    \n",
    "    # Create scatter plot\n",
    "    axes[idx].scatter(method_data['score'], method_data['rmsd'], alpha=0.5)\n",
    "    \n",
    "    # Add regression line\n",
    "    z = np.polyfit(method_data['score'], method_data['rmsd'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    axes[idx].plot(method_data['score'], p(method_data['score']), \"r--\", alpha=0.8)\n",
    "    \n",
    "    # Customize subplot\n",
    "    axes[idx].set_title(f'{method}')\n",
    "    axes[idx].set_xlabel('Score')\n",
    "    axes[idx].set_ylabel('RMSD (Å)' if idx == 0 else '')\n",
    "    \n",
    "    # Add correlation coefficient\n",
    "    corr = method_data['score'].corr(method_data['rmsd'])\n",
    "    axes[idx].text(0.05, 0.95, f'r = {corr:.2f}', \n",
    "                  transform=axes[idx].transAxes, \n",
    "                  verticalalignment='top')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = df_combined.dropna(subset=[\"score\"])[\"method\"].unique()\n",
    "\n",
    "for m in methods:\n",
    "    subset = df_combined[(df_combined[\"method\"] == m) & (df_combined[\"score\"].notna())]\n",
    "    fig = px.scatter(\n",
    "        subset,\n",
    "        x=\"score\",\n",
    "        y=\"rmsd\",\n",
    "        color=\"rmsd_≤_2å\",\n",
    "        title=f\"RMSD vs Score for {m}\",\n",
    "        width=800,\n",
    "        height=600\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical analysis for RMSD and score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "for method in df_combined['method'].unique():\n",
    "    if method == 'chai-1':\n",
    "        continue\n",
    "    for group in 'rmsd_≤_1å', 'rmsd_≤_2å', 'rmsd_≤_5å':\n",
    "        subset = df_combined[(df_combined['method'] == method) & (df_combined[group])]\n",
    "        # Filter out NaN/Inf values before correlation\n",
    "        subset_clean = subset.dropna(subset=['score', 'rmsd'])\n",
    "        subset_clean = subset_clean[~subset_clean.isin([np.inf, -np.inf]).any(axis=1)]\n",
    "        # print(f\"{method} {group} accuracy: {df_combined[(df_combined['method']==method.mean())]:.3f}\")\n",
    "        # corr = subset_clean['rmsd'].corr(subset_clean['score'])\n",
    "        pearson_corr, pearson_p = pearsonr(subset_clean['score'], subset_clean['rmsd'])\n",
    "        spearman_corr, spearman_p = spearmanr(subset_clean['score'], subset_clean['rmsd'])\n",
    "\n",
    "        print(f\"Pearson Correlation: {pearson_corr:.3f}, p-value: {pearson_p:.3f}\")\n",
    "        print(f\"Spearman Correlation: {spearman_corr:.3f}, p-value: {spearman_p:.3f}\")\n",
    "        # print(f\"{method} correlation for {group}: {corr:.3f}\")\n",
    "\n",
    "        # Scatter Plots\n",
    "        # sns.scatterplot(x='rmsd', y='score', hue='method', data=subset)\n",
    "        # plt.title('RMSD vs. Score by Docking Method')\n",
    "        # plt.show()\n",
    "\n",
    "        # linear regreesion \n",
    "    subset = (df_combined[(df_combined['method']==method)])\n",
    "    subset = subset.dropna(subset=['score', 'rmsd'])\n",
    "    subset = subset[~subset.isin([np.inf, -np.inf]).any(axis=1)]    \n",
    "    corr = subset['rmsd'].corr(subset['score'])\n",
    "    pearson_corr, pearson_p = pearsonr(subset['score'], subset['rmsd'])\n",
    "    spearman_corr, spearman_p = spearmanr(subset['score'], subset['rmsd'])\n",
    "    \n",
    "    print(f\"{method} overall correlation: \")\n",
    "    print(f\"Pearson Correlation: {pearson_corr:.3f}, p-value: {pearson_p:.3f}\")\n",
    "    print(f\"Spearman Correlation: {spearman_corr:.3f}, p-value: {spearman_p:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlations among numeric columns:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PB Validity Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUST_TEST_COLUMNS = [\n",
    "    # accuracy #\n",
    "    \"rmsd_≤_2å\",\n",
    "    # chemical validity and consistency #\n",
    "    \"mol_pred_loaded\",\n",
    "    \"mol_true_loaded\",\n",
    "    \"mol_cond_loaded\",\n",
    "    \"sanitization\",\n",
    "    \"molecular_formula\",\n",
    "    \"molecular_bonds\",\n",
    "    \"tetrahedral_chirality\",\n",
    "    \"double_bond_stereochemistry\",\n",
    "    # intramolecular validity #\n",
    "    \"bond_lengths\",\n",
    "    \"bond_angles\",\n",
    "    \"internal_steric_clash\",\n",
    "    \"aromatic_ring_flatness\",\n",
    "    \"double_bond_flatness\",\n",
    "    \"internal_energy\",\n",
    "    # intermolecular validity #\n",
    "    \"minimum_distance_to_protein\",\n",
    "    \"minimum_distance_to_organic_cofactors\",\n",
    "    \"minimum_distance_to_inorganic_cofactors\",\n",
    "    \"volume_overlap_with_protein\",\n",
    "    \"volume_overlap_with_organic_cofactors\",\n",
    "    \"volume_overlap_with_inorganic_cofactors\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN in the 'rmsd' column\n",
    "# Show the rows that contain NaN in 'rmsd' column\n",
    "# df_nan = df_combined[df_combined[\"rmsd\"].isna()]\n",
    "# print(df_nan) # 7ZHP_IQY from Chai-1 is missing\n",
    "\n",
    "df_combined_no_na = df_combined.dropna(subset=[\"rmsd\"])\n",
    "print(df_combined_no_na.shape, df_combined.shape)\n",
    "\n",
    "df_best = df_combined_no_na.loc[\n",
    "    df_combined_no_na.groupby([\"method\",\"protein\"])[\"rmsd\"].idxmin()\n",
    "].reset_index(drop=True)\n",
    "df_best.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_min_rmsd[(df_min_rmsd['protein'] == '5SAK_ZRY')])\n",
    "print(df_best[(df_best['protein'] == '5SAK_ZRY')][['method', 'rmsd']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_approach_posebusters(df, approach_name, test_cols=BUST_TEST_COLUMNS):\n",
    "    # Count how many total conformations\n",
    "    total = len(df)\n",
    "\n",
    "    # Calculate pass proportion for each test\n",
    "    results = []\n",
    "    for col in test_cols:\n",
    "        pass_count = df[col].sum()  # assuming booleans or 0/1\n",
    "        prop = pass_count / total if total else 0.0\n",
    "        results.append((col, pass_count, total, prop))\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    prop_df = pd.DataFrame(results, columns=[\"test\", \"pass_count\", \"total\", \"proportion\"])\n",
    "    prop_df[\"percentage\"] = 100.0 * prop_df[\"proportion\"]\n",
    "\n",
    "    # Sort or keep the test_cols order\n",
    "    prop_df[\"test\"] = pd.Categorical(prop_df[\"test\"], categories=test_cols, ordered=True)\n",
    "    prop_df.sort_values(\"test\", inplace=True)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    sns.barplot(data=prop_df, x=\"test\", y=\"percentage\", color=\"salmon\")\n",
    "    plt.ylim(0, 110)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"Passing (%)\")\n",
    "    plt.title(f\"PoseBusters Checks: {approach_name}\")\n",
    "    \n",
    "    # Annotate each bar with pass_count / total\n",
    "    ax = plt.gca()\n",
    "    for i, row in prop_df.iterrows():\n",
    "        ax.text(i, row[\"percentage\"] + 1,\n",
    "                f\"{int(row['pass_count'])}/{int(row['total'])}\",\n",
    "                ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_single_approach_posebusters(df_combined[(df_combined.method == 'icm')], approach_name=\"icm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_approach_posebusters(df_best[(df_best.method == 'icm')], approach_name=\"icm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_approach_posebusters(df_combined[(df_combined.method == 'surfdock')], approach_name=\"surfdock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_approach_posebusters(df_best[(df_best.method == 'surfdock')], approach_name=\"surfdock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_approach_posebusters(df_combined[(df_combined.method == 'gnina')], approach_name=\"gnina\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_approach_posebusters(df_best[(df_best.method == 'gnina')], approach_name=\"gnina\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_approach_posebusters(df_combined[(df_combined.method == 'diffdock_pocket_only')], approach_name=\"diffdock_pocket_only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_approach_posebusters(df_best[(df_best.method == 'diffdock_pocket_only')], approach_name=\"diffdock_pocket_only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: does fail in pb validity check -> large RMSD?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_boolean(df, bool_col, numeric_col):\n",
    "    \"\"\"\n",
    "    Return two Series: x_pass, x_fail\n",
    "      - x_pass: numeric_col values where bool_col == True\n",
    "      - x_fail: numeric_col values where bool_col == False\n",
    "    Also drops NaN for cleanliness.\n",
    "    \"\"\"\n",
    "    x_pass = df.loc[df[bool_col] == True,  numeric_col].dropna()\n",
    "    x_fail = df.loc[df[bool_col] == False, numeric_col].dropna()\n",
    "    return x_pass, x_fail\n",
    "\n",
    "\n",
    "def plot_boxplot_boolean_numeric(df, bool_col, numeric_col, ax=None):\n",
    "    \"\"\"\n",
    "    Create a boxplot comparing numeric_col for pass vs. fail in bool_col.\n",
    "    If ax is None, create a new figure+axes.\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(4,4))\n",
    "    \n",
    "    sns.boxplot(\n",
    "        data=df, \n",
    "        x=bool_col, \n",
    "        y=numeric_col, \n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title(f\"{numeric_col} by {bool_col}\")\n",
    "    ax.set_xlabel(f\"{bool_col} (False/True)\")\n",
    "    ax.set_ylabel(numeric_col)\n",
    "    \n",
    "    return ax  # Return the axes for further customization if needed\n",
    "\n",
    "\n",
    "from scipy.stats import mannwhitneyu, pointbiserialr\n",
    "\n",
    "def mann_whitney_test(x_pass, x_fail):\n",
    "    \"\"\"\n",
    "    Perform Mann-Whitney U test on two numeric arrays x_pass vs x_fail.\n",
    "    Returns (stat, pvalue). If one group is empty, return (None, None).\n",
    "    \"\"\"\n",
    "    if len(x_pass) > 0 and len(x_fail) > 0:\n",
    "        stat, pval = mannwhitneyu(x_pass, x_fail, alternative=\"two-sided\")\n",
    "        return stat, pval\n",
    "    return None, None\n",
    "\n",
    "def point_biserial(df, bool_col, numeric_col):\n",
    "    \"\"\"\n",
    "    Compute point-biserial correlation between bool_col (boolean) and numeric_col.\n",
    "    Returns (corr, pval). If not enough data, returns (None, None).\n",
    "    \"\"\"\n",
    "    # convert bool -> 0/1\n",
    "    y_bool = df[bool_col].astype(int)\n",
    "    x_num  = df[numeric_col]\n",
    "    mask = x_num.notna()\n",
    "    \n",
    "    if mask.sum() < 2:\n",
    "        return None, None\n",
    "    \n",
    "    corr, pval = pointbiserialr(y_bool[mask], x_num[mask])\n",
    "    return corr, pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_boolean_numeric_pair(df, bool_col, numeric_col, plot=True):\n",
    "    \"\"\"\n",
    "    Analyze how numeric_col differs based on bool_col pass/fail.\n",
    "    - Plots a boxplot if plot=True.\n",
    "    - Computes Mann-Whitney and point-biserial correlation.\n",
    "    Returns a dict with results.\n",
    "    \"\"\"\n",
    "    # Split data\n",
    "    x_pass, x_fail = split_by_boolean(df, bool_col, numeric_col)\n",
    "\n",
    "    # Plot if desired\n",
    "    ax = None\n",
    "    if plot:\n",
    "        ax = plot_boxplot_boolean_numeric(df, bool_col, numeric_col)\n",
    "        plt.show()\n",
    "\n",
    "    # Mann-Whitney\n",
    "    mw_stat, mw_p = mann_whitney_test(x_pass, x_fail)\n",
    "\n",
    "    # Point-biserial\n",
    "    corr, corr_p = point_biserial(df, bool_col, numeric_col)\n",
    "\n",
    "    # Prepare a summary\n",
    "    results = {\n",
    "        \"bool_col\": bool_col,\n",
    "        \"numeric_col\": numeric_col,\n",
    "        \"mannwhitney_stat\": mw_stat,\n",
    "        \"mannwhitney_p\": mw_p,\n",
    "        \"pointbiserial_corr\": corr,\n",
    "        \"pointbiserial_p\": corr_p,\n",
    "        \"n_pass\": len(x_pass),\n",
    "        \"n_fail\": len(x_fail),\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_boolean_numeric_pipeline(\n",
    "    df, \n",
    "    boolean_checks, \n",
    "    numeric_columns, \n",
    "    do_plots=False\n",
    "):\n",
    "    \"\"\"\n",
    "    For each bool_col in boolean_checks, and each numeric_col in numeric_columns,\n",
    "    call analyze_boolean_numeric_pair, collect stats in a DataFrame.\n",
    "    If do_plots=True, show the boxplots as well.\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "\n",
    "    for bool_col in boolean_checks:\n",
    "        for numeric_col in numeric_columns:\n",
    "            res = analyze_boolean_numeric_pair(\n",
    "                df, bool_col, numeric_col, plot=do_plots\n",
    "            )\n",
    "            all_results.append(res)\n",
    "\n",
    "    # Convert list of dicts into a DataFrame\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = run_boolean_numeric_pipeline(\n",
    "    df_combined,\n",
    "    [\"minimum_distance_to_protein\", \"volume_overlap_with_protein\", \"internal_steric_clash\"],\n",
    "    [\"rmsd\"],\n",
    "    do_plots=True\n",
    ")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_boolean_numeric_pipeline(\n",
    "    df_combined[df_combined['method'] == 'icm'],\n",
    "    [\"minimum_distance_to_protein\", \"volume_overlap_with_protein\", \"internal_steric_clash\"],\n",
    "    [\"score\"],\n",
    "    do_plots=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_boolean_numeric_pipeline(\n",
    "    df_combined[df_combined['method'] == 'surfdock'],\n",
    "    [\"minimum_distance_to_protein\", \"volume_overlap_with_protein\", \"internal_steric_clash\"],\n",
    "    [\"score\"],\n",
    "    do_plots=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_mask = df_combined_no_na[\"minimum_distance_to_protein\"]  # True/False\n",
    "fail_mask = ~pass_mask\n",
    "#### Visual analysis\n",
    "print(df_combined.columns)\n",
    "sns.boxplot(data=df_combined, x=\"minimum_distance_to_protein\", y=\"rmsd\")\n",
    "sns.kdeplot(data=df_combined_no_na[pass_mask], x=\"rmsd\", label=\"Pass\")\n",
    "sns.kdeplot(data=df_combined_no_na[fail_mask], x=\"rmsd\", label=\"Fail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Analysi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "pass_rmsd = df_best.loc[pass_mask, \"rmsd\"]\n",
    "fail_rmsd = df_best.loc[fail_mask, \"rmsd\"]\n",
    "stat, pval = mannwhitneyu(pass_rmsd, fail_rmsd, alternative=\"two-sided\")\n",
    "print(\"Mann-Whitney U test p-value:\", pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pointbiserialr\n",
    "\n",
    "fail_boolean = df_best[\"minimum_distance_to_protein\"].astype(int)  # 1=pass, 0=fail (or vice versa)\n",
    "rmsd_vals = df_best[\"rmsd\"]\n",
    "corr, pval = pointbiserialr(fail_boolean, rmsd_vals)\n",
    "print(\"Point-biserial correlation:\", corr, \"p-value:\", pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Analysi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\"rmsd\", \"score\", \"some_other_metric\"]\n",
    "corr_matrix = df_all[numeric_cols].corr()\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-protein Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Success rate per protein**\n",
    "Use this to  see which proteins are “easy” or “hard” for each metho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_protein_method = df_combined.groupby([\"protein\",\"method\"])[\"rmsd_≤_2å\"].mean().reset_index()\n",
    "per_protein_method.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_pivot = per_protein_method.pivot(\n",
    "    index=\"protein\", \n",
    "    columns=\"method\", \n",
    "    values=\"rmsd_≤_2å\"\n",
    ")\n",
    "success_pivot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Minimum RMSD among top-N poses:**  compute the minimum RMSD per (protein, method) to see the best that method can do for each protein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rmsd = df_combined.groupby([\"protein\",\"method\"])[\"rmsd\"].min().reset_index()\n",
    "best_rmsd_pivot = best_rmsd.pivot(index=\"protein\", columns=\"method\", values=\"rmsd\")\n",
    "best_rmsd_pivot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairwise or overlap analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Which proteins are solved by multiple methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined[\"success\"] = df_combined[\"rmsd_≤_2å\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each protein, count how many methods succeeded\n",
    "success_counts = (\n",
    "    df_combined[df_combined[\"success\"] == True]\n",
    "    .groupby([\"protein\",\"method\"])[\"success\"]\n",
    "    .first()  # or .any(), if multiple rows\n",
    "    .unstack(fill_value=False)\n",
    ")\n",
    "success_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complementary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# Suppose success_counts is a DataFrame with boolean columns for each method\n",
    "# Example columns: [\"icm\", \"diffdock\", \"chai-1\", \"diffdock_pocket_only\", \"surfdock\"]\n",
    "\n",
    "methods = success_counts.columns.tolist()  # or list them explicitly if you want a specific subset\n",
    "pairs = list(itertools.combinations(methods, 2))\n",
    "\n",
    "# Dictionary to store pairwise overlaps\n",
    "overlap_dict = {}\n",
    "\n",
    "for (m1, m2) in pairs:\n",
    "    # Count how many entries are True for BOTH methods\n",
    "    overlap_count = success_counts[[m1, m2]].all(axis=1).sum()\n",
    "    overlap_dict[(m1, m2)] = overlap_count\n",
    "\n",
    "# Convert the dictionary into a DataFrame for better readability\n",
    "overlap_df = pd.DataFrame.from_dict(overlap_dict, orient='index', columns=['Overlap_Count'])\n",
    "\n",
    "# Optionally sort by overlap count (descending)\n",
    "overlap_df = overlap_df.sort_values(by='Overlap_Count', ascending=False)\n",
    "\n",
    "print(overlap_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_counts\n",
    "methods = success_counts.columns.tolist()\n",
    "pairwise_df = pd.DataFrame(\n",
    "    0, index=methods, columns=methods, \n",
    "    dtype=\"Int64\"  # or int if you prefer\n",
    ")\n",
    "\n",
    "for m1 in methods:\n",
    "    for m2 in methods:\n",
    "        if m1 == m2:\n",
    "            # Some people prefer to leave diagonal empty or None\n",
    "            pairwise_df.loc[m1, m2] = pd.NA\n",
    "        else:\n",
    "            # Count proteins that method m1 succeeded but m2 did not\n",
    "            mask = success_counts[m1] & (~success_counts[m2])\n",
    "            pairwise_df.loc[m1, m2] = mask.sum()\n",
    "\n",
    "pairwise_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### figure out the protein name for specail cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_complementary_proteins(success_counts, method_i, method_j):\n",
    "    \"\"\"\n",
    "    Get proteins where method_i succeeds and method_j fails.\n",
    "    \"\"\"\n",
    "    mask = success_counts[method_i] & (~success_counts[method_j])\n",
    "    complementary_proteins = success_counts[mask].index.tolist()\n",
    "    return complementary_proteins\n",
    "\n",
    "# Example usage for methods 'icm' and 'diffdock'\n",
    "method_i = 'diffdock_pocket_only'\n",
    "method_j = 'icm'\n",
    "complementary_proteins = get_complementary_proteins(success_counts, method_i, method_j)\n",
    "print(f\"Proteins where {method_i} succeeds and {method_j} fails: {complementary_proteins}\")\n",
    "\n",
    "method_i, method_j = \"chai-1\", \"icm\"\n",
    "complementary_proteins  = get_complementary_proteins(success_counts, 'chai-1', 'icm')\n",
    "print(f\"Proteins where {method_i} succeeds and {method_j} fails: {complementary_proteins}\")\n",
    "\n",
    "method_i, method_j = 'icm', 'diffdock_pocket_only'\n",
    "complementary_proteins  = get_complementary_proteins(success_counts, f'{method_i}', f'{method_j}')\n",
    "print(f\"Proteins where {method_i} succeeds and {method_j}m fails: {complementary_proteins}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Proteins where {method_i} succeeds and {method_j} fails: {complementary_proteins}\")\n",
    "# List of methods to check for consistent failure\n",
    "methods_to_check = ['icm', 'gnina']\n",
    "\n",
    "# Find proteins that failed for all specified methods\n",
    "consistent_failures = success_counts[methods_to_check].any(axis=1) == False\n",
    "failed_proteins = success_counts[consistent_failures].index.tolist()\n",
    "\n",
    "print(f\"Proteins that consistently failed for methods {methods_to_check}: {failed_proteins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_i = \"icm\"\n",
    "method_j = \"gnina\"\n",
    "mask_i = (~success_counts[method_i])\n",
    "mask_j = (~success_counts[method_j])\n",
    "fail_i = success_counts[mask_i].index.tolist()\n",
    "fail_j = success_counts[mask_j].index.tolist()\n",
    "print(f\"Proteins that failed for {method_i}: {fail_i}\")\n",
    "print(f\"Proteins that failed for {method_j}: {fail_j}\")\n",
    "intersection = set(fail_i).intersection(fail_j)\n",
    "print(f\"Proteins that failed for both {method_i} and {method_j}: {intersection}\")\n",
    "\n",
    "def get_all_failure_proteins(success_counts, methods):\n",
    "    \"\"\"\n",
    "    Get proteins that failed for all specified methods.\n",
    "    Returns a list of protein names.\n",
    "    \"\"\"\n",
    "    if not methods:\n",
    "        return []\n",
    "        \n",
    "    # Get proteins that failed for the first method\n",
    "    method = methods[0]\n",
    "    mask = (~success_counts[method])\n",
    "    all_failure_set = set(success_counts[mask].index.tolist())\n",
    "    \n",
    "    # Intersect with failures from other methods\n",
    "    for method in methods[1:]:\n",
    "        mask = (~success_counts[method])\n",
    "        fail_proteins = set(success_counts[mask].index.tolist())\n",
    "        all_failure_set = all_failure_set.intersection(fail_proteins)\n",
    "        \n",
    "    return list(all_failure_set)\n",
    "\n",
    "# Usage example:\n",
    "failures = get_all_failure_proteins(success_counts, ['diffdock', 'diffdock_pocket_only'])\n",
    "print(f\"Proteins that failed for all methods {['diffdock', 'chai-1']}: {failures}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_i = \"icm\"\n",
    "method_j = \"gnina\"\n",
    "mask_i = (~success_counts[method_i])\n",
    "mask_j = (~success_counts[method_j])\n",
    "fail_i = success_counts[mask_i].index.tolist()\n",
    "fail_j = success_counts[mask_j].index.tolist()\n",
    "print(f\"Proteins that failed for {method_i}: {fail_i}\")\n",
    "print(f\"Proteins that failed for {method_j}: {fail_j}\")\n",
    "intersection = set(fail_i).intersection(fail_j)\n",
    "print(f\"Proteins that failed for both {method_i} and {method_j}: {intersection}\")\n",
    "\n",
    "def get_all_failure_proteins(success_counts, methods):\n",
    "    \"\"\"\n",
    "    Get proteins that failed for all specified methods.\n",
    "    Returns a list of protein names.\n",
    "    \"\"\"\n",
    "    if not methods:\n",
    "        return []\n",
    "        \n",
    "    # Get proteins that failed for the first method\n",
    "    method = methods[0]\n",
    "    mask = (~success_counts[method])\n",
    "    all_failure_set = set(success_counts[mask].index.tolist())\n",
    "    \n",
    "    # Intersect with failures from other methods\n",
    "    for method in methods[1:]:\n",
    "        mask = (~success_counts[method])\n",
    "        fail_proteins = set(success_counts[mask].index.tolist())\n",
    "        all_failure_set = all_failure_set.intersection(fail_proteins)\n",
    "        \n",
    "    return list(all_failure_set)\n",
    "\n",
    "# Usage example:\n",
    "failures = get_all_failure_proteins(success_counts, ['diffdock', 'diffdock_pocket_only'])\n",
    "print(f\"Proteins that failed for all methods {['diffdock', 'chai-1']}: {failures}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_i = \"icm\"\n",
    "method_j = \"gnina\"\n",
    "mask_i = (~success_counts[method_i])\n",
    "mask_j = (~success_counts[method_j])\n",
    "fail_i = success_counts[mask_i].index.tolist()\n",
    "fail_j = success_counts[mask_j].index.tolist()\n",
    "print(f\"Proteins that failed for {method_i}: {fail_i}\")\n",
    "print(f\"Proteins that failed for {method_j}: {fail_j}\")\n",
    "intersection = set(fail_i).intersection(fail_j)\n",
    "print(f\"Proteins that failed for both {method_i} and {method_j}: {intersection}\")\n",
    "\n",
    "def get_all_failure_proteins(success_counts, methods):\n",
    "    \"\"\"\n",
    "    Get proteins that failed for all specified methods.\n",
    "    Returns a list of protein names.\n",
    "    \"\"\"\n",
    "    if not methods:\n",
    "        return []\n",
    "        \n",
    "    # Get proteins that failed for the first method\n",
    "    method = methods[0]\n",
    "    mask = (~success_counts[method])\n",
    "    all_failure_set = set(success_counts[mask].index.tolist())\n",
    "    \n",
    "    # Intersect with failures from other methods\n",
    "    for method in methods[1:]:\n",
    "        mask = (~success_counts[method])\n",
    "        fail_proteins = set(success_counts[mask].index.tolist())\n",
    "        all_failure_set = all_failure_set.intersection(fail_proteins)\n",
    "        \n",
    "    return list(all_failure_set)\n",
    "\n",
    "# Usage example:\n",
    "failures = get_all_failure_proteins(success_counts, ['diffdock', 'diffdock_pocket_only'])\n",
    "print(f\"Proteins that failed for all methods {['diffdock', 'chai-1']}: {failures}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_i = \"icm\"\n",
    "method_j = \"gnina\"\n",
    "mask_i = (~success_counts[method_i])\n",
    "mask_j = (~success_counts[method_j])\n",
    "fail_i = success_counts[mask_i].index.tolist()\n",
    "fail_j = success_counts[mask_j].index.tolist()\n",
    "print(f\"Proteins that failed for {method_i}: {fail_i}\")\n",
    "print(f\"Proteins that failed for {method_j}: {fail_j}\")\n",
    "intersection = set(fail_i).intersection(fail_j)\n",
    "print(f\"Proteins that failed for both {method_i} and {method_j}: {intersection}\")\n",
    "\n",
    "def get_all_failure_proteins(success_counts, methods):\n",
    "    \"\"\"\n",
    "    Get proteins that failed for all specified methods.\n",
    "    Returns a list of protein names.\n",
    "    \"\"\"\n",
    "    if not methods:\n",
    "        return []\n",
    "        \n",
    "    # Get proteins that failed for the first method\n",
    "    method = methods[0]\n",
    "    mask = (~success_counts[method])\n",
    "    all_failure_set = set(success_counts[mask].index.tolist())\n",
    "    \n",
    "    # Intersect with failures from other methods\n",
    "    for method in methods[1:]:\n",
    "        mask = (~success_counts[method])\n",
    "        fail_proteins = set(success_counts[mask].index.tolist())\n",
    "        all_failure_set = all_failure_set.intersection(fail_proteins)\n",
    "        \n",
    "    return list(all_failure_set)\n",
    "\n",
    "# Usage example:\n",
    "failures = get_all_failure_proteins(success_counts, ['diffdock', 'diffdock_pocket_only'])\n",
    "print(f\"Proteins that failed for all methods {['diffdock', 'chai-1']}: {failures}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from upsetplot import from_contents, UpSet\n",
    "\n",
    "# 2) Make sets of proteins for each method\n",
    "df_solved = success_counts.copy()\n",
    "methods = [\"icm\", \"diffdock\", \"gnina\", \"vina\", \"surfdock\", \"diffdock_pocket_only\"]\n",
    "method_sets = {}\n",
    "\n",
    "for method in methods:\n",
    "    mask = (success_counts[method])\n",
    "    method_sets[method] = set( success_counts[mask].index.tolist())\n",
    "\n",
    "# 3) Convert to an upsetplot-compatible structure\n",
    "upset_data = from_contents(method_sets)\n",
    "\n",
    "# 4) Create the UpSet figure\n",
    "UpSet(upset_data, show_counts=True, subset_size='count', sort_categories_by=None).plot()\n",
    "plt.suptitle(\"Overlap of Proteins Solved by Different Methods\")\n",
    "plt.show()\n",
    "\n",
    "# Synergy example:\n",
    "# Suppose you want to see proteins that exactly 'icm_solved' or 'diffdock_solved' but not the others:\n",
    "# You can check the UpSet intersection or do a quick filter in the data:\n",
    "df_solved[\"icm_or_diffdock\"] = df_solved[\"icm\"] | df_solved[\"diffdock\"]\n",
    "df_solved[\"others_solved\"] = df_solved[\"gnina\"] | df_solved[\"vina\"] | df_solved[\"surfdock\"]\n",
    "synergy_df = df_solved[ (df_solved[\"icm_or_diffdock\"]) & (~df_solved[\"others_solved\"]) ]\n",
    "print(\"Proteins solved by (ICM or DiffDock) but NOT by others:\\n\", synergy_df[\"protein\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from upsetplot import from_indicators\n",
    "# Example: we have booleans for 5 methods\n",
    "# methods = [\"icm\", \"diffdock\", \"gnina\", \"surfdock\", \"vina\"]\n",
    "\n",
    "# 1) For each row (protein), count how many methods = True\n",
    "df_solved[\"num_methods\"] = df_solved[methods].sum(axis=1)\n",
    "\n",
    "# 2) Filter to keep only rows with up to 2 methods = True\n",
    "df_filtered = df_solved[df_solved[\"num_methods\"] <= 2].copy()\n",
    "\n",
    "# 3) Build an UpSet-friendly structure. \n",
    "#    One easy way is from_indicators: for each method col, it must be boolean \n",
    "#    for \"icm\" or \"diffdock\", etc.\n",
    "upset_data = from_indicators(methods, data=df_filtered[methods])\n",
    "\n",
    "# 4) Create and plot the UpSet\n",
    "UpSet(\n",
    "    upset_data, \n",
    "    show_counts=True, \n",
    "    subset_size='count', \n",
    "    sort_categories_by=None\n",
    ").plot()\n",
    "\n",
    "plt.suptitle(\"UpSet: Intersection of at most 2 methods\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-depth analysis for failed cases for ICM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_proteins = success_counts[success_counts['icm'] == False].index.tolist()\n",
    "print(f\"Proteins where ICM failed: {failed_proteins}\")\n",
    "\n",
    "# Optional: See full details for these proteins\n",
    "icm_failures = df_combined[\n",
    "    (df_combined['protein'].isin(failed_proteins)) & \n",
    "    (df_combined['method'] == 'icm')\n",
    "]\n",
    "# display(icm_failures)\n",
    "print(len(icm_failures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get ICM failed proteins\n",
    "icm_failed = success_counts[success_counts['icm'] == False].index\n",
    "\n",
    "# 2. Create comparison table for failed proteins\n",
    "failure_comparison = success_counts.loc[icm_failed]\n",
    "\n",
    "# 3. Display results\n",
    "print(\"Success/Failure patterns for ICM-failed proteins:\")\n",
    "display(failure_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank-1 Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in [\"icm\", \"diffdock\", \"chai-1\", \"vina\", \"gnina\"]:\n",
    "    tmp = df_combined.loc[df_combined['method']== method]\n",
    "    tmp = tmp.loc[tmp['rank'] == 1]\n",
    "    print(tmp['success'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose we only compare rank=1 for each method\n",
    "# (or min RMSD across top5)\n",
    "# Then pivot:\n",
    "pivot_df = df_combined[df_combined[\"rank\"]==1].pivot(\n",
    "    index=\"protein\",\n",
    "    columns=\"method\",\n",
    "    values=\"rmsd\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for rank 1 results\n",
    "rank1_df = df_combined[df_combined['rank'] == 1]\n",
    "\n",
    "# Calculate success rates for different thresholds\n",
    "melted = rank1_df.melt(id_vars='method', \n",
    "                       value_vars=['rmsd_≤_1å', 'rmsd_≤_2å', 'rmsd_≤_5å'],\n",
    "                       var_name='RMSD_Group',\n",
    "                       value_name='Is_Accurate')\n",
    "\n",
    "# Calculate proportion for each method and threshold\n",
    "prop = melted.groupby(['method', 'RMSD_Group'])['Is_Accurate'].mean().reset_index()\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=prop, x='method', y='Is_Accurate', hue='RMSD_Group')\n",
    "plt.ylabel('Proportion of Accurate Poses')\n",
    "plt.title('Success Rate by Method (Rank 1 Poses Only)')\n",
    "plt.legend(title='RMSD Group', labels=['RMSD ≤ 1 Å', 'RMSD ≤ 2 Å', 'RMSD ≤ 5 Å'])\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['rmsd'] = np.log1p(df_combined['rmsd'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot_rmsd_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots for all three comparisons\n",
    "fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, figsize=(15, 5), sharex=True, sharey=True)\n",
    "\n",
    "# ICM vs DiffDock\n",
    "sns.scatterplot(data=pivot_df, x='icm', y='diffdock_pocket_only', ax=ax1)\n",
    "ax1.set_xlabel('ICM RMSD (Å)')\n",
    "ax1.set_ylabel('DiffDock RMSD (Å)')\n",
    "ax1.set_title('ICM vs DiffDock RMSD')\n",
    "\n",
    "# ICM vs Chai-1\n",
    "sns.scatterplot(data=pivot_df, x='icm', y='chai-1', ax=ax2)\n",
    "ax2.set_xlabel('ICM RMSD (Å)')\n",
    "ax2.set_ylabel('Chai-1 RMSD (Å)')\n",
    "ax2.set_title('ICM vs Chai-1 RMSD')\n",
    "\n",
    "# Chai-1 vs DiffDock\n",
    "sns.scatterplot(data=pivot_df, x='surfdock', y='diffdock_pocket_only', ax=ax3)\n",
    "ax3.set_xlabel('Chai-1 RMSD (Å)')\n",
    "ax3.set_ylabel('DiffDock RMSD (Å)')\n",
    "ax3.set_title('Chai-1 vs DiffDock RMSD')\n",
    "\n",
    "# Diffdock vs gnina\n",
    "sns.scatterplot(data=pivot_df, x='chai-1', y='gnina', ax=ax4)\n",
    "ax4.set_xlabel('Chai-1 RMSD (Å)')\n",
    "ax4.set_ylabel('gnina RMSD (Å)')\n",
    "ax4.set_title('Chai-1 vs gnina RMSD')\n",
    "\n",
    "# chai-1 vs surfdock\n",
    "sns.scatterplot(data=pivot_df, x='icm', y='surfdock', ax=ax5)\n",
    "ax5.set_xlabel('ICM RMSD (Å)')\n",
    "ax5.set_ylabel('surfdock RMSD (Å)')\n",
    "ax5.set_title('ICM vs surfdock RMSD')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots for all three comparisons\n",
    "fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, figsize=(15, 5), sharex=True, sharey=True)\n",
    "\n",
    "# ICM vs DiffDock\n",
    "sns.scatterplot(data=pivot_df, x='icm', y='diffdock_pocket_only', ax=ax1)\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_xlabel('ICM RMSD (Å)')\n",
    "ax1.set_ylabel('DiffDock RMSD (Å)')\n",
    "ax1.set_title('ICM vs DiffDock RMSD')\n",
    "\n",
    "# ICM vs Chai-1\n",
    "sns.scatterplot(data=pivot_df, x='icm', y='chai-1', ax=ax2)\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_xlabel('ICM RMSD (Å)')\n",
    "ax2.set_ylabel('Chai-1 RMSD (Å)')\n",
    "ax2.set_title('ICM vs Chai-1 RMSD')\n",
    "\n",
    "# Chai-1 vs DiffDock\n",
    "sns.scatterplot(data=pivot_df, x='surfdock', y='diffdock_pocket_only', ax=ax3)\n",
    "ax3.set_xscale('log')\n",
    "ax3.set_yscale('log')\n",
    "ax3.set_xlabel('Chai-1 RMSD (Å)')\n",
    "ax3.set_ylabel('Diffdock_pocket_only RMSD (Å)')\n",
    "ax3.set_title('Chai-1 vs DiffDock RMSD')\n",
    "\n",
    "# Diffdock vs gnina\n",
    "sns.scatterplot(data=pivot_df, x='chai-1', y='gnina', ax=ax4)\n",
    "ax4.set_xscale('log')\n",
    "ax4.set_yscale('log')\n",
    "ax4.set_xlabel('Chai-1 RMSD (Å)')\n",
    "ax4.set_ylabel('gnina RMSD (Å)')\n",
    "ax4.set_title('Chai-1 vs gnina RMSD')\n",
    "\n",
    "# chai-1 vs surfdock\n",
    "sns.scatterplot(data=pivot_df, x='icm', y='surfdock', ax=ax5)\n",
    "ax5.set_xscale('log')\n",
    "ax5.set_yscale('log')\n",
    "ax5.set_xlabel('ICM RMSD (Å)')\n",
    "ax5.set_ylabel('surfdock RMSD (Å)')\n",
    "ax5.set_title('ICM vs surfdock RMSD')\n",
    "\n",
    "for ax in [ax1, ax2, ax3, ax4, ax5]:\n",
    "    ax.set_aspect('equal', 'box')  # or 'datalim', see below\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    pivot_df,\n",
    "    x=\"icm\",\n",
    "    y=\"diffdock_pocket_only\",\n",
    "    hover_name=pivot_df.index\n",
    ")\n",
    "fig.update_traces(marker=dict(size=12, opacity=0.8))\n",
    "\n",
    "# Make both axes use the same scale:\n",
    "fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    pivot_df,\n",
    "    x=\"surfdock\",\n",
    "    y=\"diffdock_pocket_only\",\n",
    "    hover_name=pivot_df.index\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    pivot_df,\n",
    "    x=\"icm\",\n",
    "    y=\"surfdock\",\n",
    "    hover_name=pivot_df.index\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model-Fitting or Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "df_subset = df_all.dropna(subset=[\"rmsd\", \"num_rotatable_bonds\"])\n",
    "model = smf.ols(\"rmsd ~ num_rotatable_bonds + C(method)\", data=df_subset).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plinder comparative analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the data annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_annot_df = pd.read_csv('plinder_test.csv')\n",
    "test_annot_df[0:5].to_csv('plinder_sample_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_method[:5].to_csv('plinder_method_sample_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molpal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
