{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from Bio.Align import PairwiseAligner\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(215, 127) (279, 127)\n",
      "(214, 253)\n"
     ]
    }
   ],
   "source": [
    "diffdock_df = pd.read_csv(\"/Users/aoxu/projects/DrugDiscovery/PoseBench/forks/DiffDock/inference/diffdock_posebusters_benchmark_output_orig_structure_2/bust_results_aggregated.csv\")\n",
    "df_pb = pd.read_csv(\"/Users/aoxu/projects/DrugDiscovery/PoseBench/forks/ICM/inference/icm_manual_posebusters_benchmark_outputs_1/bust_results_aggregated.csv\")\n",
    "print(diffdock_df.shape, df_pb.shape)\n",
    "\n",
    "# If each df has columns [\"protein\",\"ligand\",\"rmsd\", \"Score\", \"is_success\"], etc.\n",
    "merged_df = pd.merge(df_pb, diffdock_df,\n",
    "                     on=[\"protein\"],\n",
    "                     suffixes=(\"_icm\",\"_diffdock\"))\n",
    "print(merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_proteins = merged_df[ (~merged_df[\"rmsd_≤_2å_icm\"])]['protein'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fasta_file(fasta_path):\n",
    "    with open(fasta_path, \"r\") as file:\n",
    "        for record in SeqIO.parse(file, \"fasta\"):\n",
    "            print(f\">{record.id}\")\n",
    "            print(record.seq)\n",
    "\n",
    "# Example usage:\n",
    "seq_file_path = \"/Users/aoxu/projects/DrugDiscovery/PoseBench/forks/ICM/inference/icm_manual_posebusters_benchmark_outputs_1/seqs\"\n",
    "read_fasta_file(seq_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence-based clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sequence-based clustering example:\n",
    "1) Read multiple protein FASTA files (one sequence per file).\n",
    "2) Compute pairwise sequence identity.\n",
    "3) Build a distance matrix and perform hierarchical clustering.\n",
    "\"\"\"\n",
    "\n",
    "def read_fasta_file(fasta_path):\n",
    "    \"\"\"\n",
    "    Read a single FASTA file that contains multiple sequences.\n",
    "    Returns:\n",
    "      names:   list of sequence IDs (from FASTA headers)\n",
    "      seqs:    list of sequence strings\n",
    "    \"\"\"\n",
    "    names = []\n",
    "    seqs = []\n",
    "    with open(fasta_path, \"r\") as handle:\n",
    "        for record in SeqIO.parse(handle, \"fasta\"):\n",
    "            names.append(record.id)       # e.g. \"7ZZW_KKW_chain_0\"\n",
    "            seqs.append(str(record.seq))  # the actual sequence\n",
    "    return names, seqs\n",
    "\n",
    "def read_fasta_files(fasta_dir):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      names: list of protein names (filename-based)\n",
    "      sequences: list of Biopython Seq objects (or strings)\n",
    "    \"\"\"\n",
    "    names = []\n",
    "    sequences = []\n",
    "    for fasta_path in glob.glob(os.path.join(fasta_dir, \"*.fasta\")):\n",
    "        protein_name = os.path.splitext(os.path.basename(fasta_path))[0]\n",
    "        record = next(SeqIO.parse(fasta_path, \"fasta\"))  # assume 1 seq per file\n",
    "        names.append(protein_name)\n",
    "        sequences.append(str(record.seq))\n",
    "    return names, sequences\n",
    "\n",
    "def compute_identity(seqA, seqB):\n",
    "    \"\"\"\n",
    "    Returns fraction identity between seqA and seqB.\n",
    "    Using global pairwise alignment via Biopython PairwiseAligner.\n",
    "    \"\"\"\n",
    "    aligner = PairwiseAligner()\n",
    "    aligner.mode = \"global\"\n",
    "    alignments = aligner.align(seqA, seqB)\n",
    "    best_aln = alignments[0]\n",
    "    # best_aln.score is alignment score, but we want identity\n",
    "    # For simplicity, let's count matches:\n",
    "    matches = 0\n",
    "    aligned_length = 0\n",
    "    seqA_aln = best_aln.aligned[0]  # list of (start, end) blocks in seqA\n",
    "    seqB_aln = best_aln.aligned[1]  # list of (start, end) blocks in seqB\n",
    "    # We'll reconstruct the alignment as best as we can:\n",
    "    alignment_strA = []\n",
    "    alignment_strB = []\n",
    "    for (startA, endA), (startB, endB) in zip(seqA_aln, seqB_aln):\n",
    "        alignment_strA.append(seqA[startA:endA])\n",
    "        alignment_strB.append(seqB[startB:endB])\n",
    "    aligned_seqA = \"\".join(alignment_strA)\n",
    "    aligned_seqB = \"\".join(alignment_strB)\n",
    "\n",
    "    for a, b in zip(aligned_seqA, aligned_seqB):\n",
    "        if a == b:\n",
    "            matches += 1\n",
    "        aligned_length += 1\n",
    "\n",
    "    return matches / aligned_length if aligned_length > 0 else 0.0\n",
    "\n",
    "def sequence_distance_matrix(sequences):\n",
    "    \"\"\"\n",
    "    Build NxN matrix of (1 - identity).\n",
    "    \"\"\"\n",
    "    n = len(sequences)\n",
    "    dist_matrix = np.zeros((n, n), dtype=float)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            identity = compute_identity(sequences[i], sequences[j])\n",
    "            dist = 1.0 - identity\n",
    "            dist_matrix[i, j] = dist\n",
    "            dist_matrix[j, i] = dist\n",
    "    return dist_matrix\n",
    "\n",
    "def cluster_sequences(fasta_dir, selected_proteins=None):\n",
    "    names, seqs = read_fasta_file(fasta_dir)\n",
    "    if selected_proteins is not None:\n",
    "        # Filter sequences by protein names\n",
    "        selected_indices = [i for i, name in enumerate(names) if name.split('_chain')[0] in selected_proteins]\n",
    "        names = [names[i] for i in selected_indices]\n",
    "        seqs = [seqs[i] for i in selected_indices]\n",
    "    dist_mat = sequence_distance_matrix(seqs)\n",
    "    # Convert to condensed form for scipy linkage:\n",
    "    # upper triangle of dist_mat (without diagonal)\n",
    "    from scipy.spatial.distance import squareform\n",
    "    dist_condensed = squareform(dist_mat, checks=False)\n",
    "\n",
    "    Z = linkage(dist_condensed, method=\"average\")  # hierarchical clustering\n",
    "    # Plot dendrogram\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    dendrogram(Z, labels=names, leaf_rotation=90)\n",
    "    plt.title(\"Sequence-based clustering (average linkage)\")\n",
    "    plt.show()\n",
    "    return Z\n",
    "\n",
    "# Example usage:\n",
    "seq_file_path = \"/Users/aoxu/projects/DrugDiscovery/PoseBench/data/posebusters_benchmark_set/posebusters_benchmark_sequences.fasta\"\n",
    "cluster_sequences(seq_file_path, selected_proteins=failed_proteins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Structure-Based Clustering (Global 3D)\n",
    "Cluster proteins by structural similarity, using RMSD or TM-score from pairwise structure alignment. (TM-align)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Structure-based clustering:\n",
    "1) For each pair of PDB files, run TM-align (or an equivalent) to get RMSD or TM-score.\n",
    "2) Build an NxN distance matrix.\n",
    "3) Perform hierarchical clustering or another method.\n",
    "\"\"\"\n",
    "\n",
    "import subprocess\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run_tmalign(pdbA, pdbB, tmalign_bin=\"TMalign\"):\n",
    "    \"\"\"\n",
    "    Run TM-align and parse RMSD or TM-score from stdout.\n",
    "    Returns (rmsd, tm_score).\n",
    "    \"\"\"\n",
    "    cmd = [tmalign_bin, pdbA, pdbB]\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
    "    lines = result.stdout.splitlines()\n",
    "\n",
    "    rmsd_val = None\n",
    "    tm_val = None\n",
    "    for line in lines:\n",
    "        if line.startswith(\"RMSD of the common residues\"):\n",
    "            # e.g. \"RMSD of the common residues=   2.12\"\n",
    "            parts = line.split(\"=\")\n",
    "            rmsd_val = float(parts[1])\n",
    "        elif line.startswith(\"TM-score=\"):\n",
    "            # e.g. \"TM-score= 0.45\"\n",
    "            parts = line.split(\"=\")\n",
    "            tm_val = float(parts[1].split()[0])\n",
    "    return rmsd_val, tm_val\n",
    "\n",
    "def load_pdb(pdb_dir, selected_proteins=None, cropped=''):\n",
    "    \"\"\"\n",
    "    retrieve the path for the pdb files in the pdb directory\n",
    "    \"\"\"\n",
    "    protein_names = os.listdir(pdb_dir)\n",
    "    if selected_proteins is not None:\n",
    "        protein_paths = [os.path.join(pdb_dir, protein_name, f\"{protein_name}_protein_{cropped}.pdb\") for protein_name in selected_proteins]\n",
    "    else:\n",
    "        protein_paths = [os.path.join(pdb_dir, protein_name, f\"{protein_name}_protein_{cropped}.pdb\") for protein_name in protein_names]\n",
    "\n",
    "    return protein_paths\n",
    "\n",
    "def build_structure_distance_matrix(pdb_dir, selected_proteins=None, cropped=''):\n",
    "    \"\"\"\n",
    "    For each PDB in pdb_dir, run pairwise TMalign, store RMSD as distance.\n",
    "    \"\"\"\n",
    "    names = os.listdir(pdb_dir)\n",
    "    if selected_proteins is not None:\n",
    "        pdb_paths = [os.path.join(pdb_dir, protein_name, f\"{protein_name}_protein_{cropped}.pdb\") for protein_name in selected_proteins]\n",
    "    else:\n",
    "        pdb_paths = [os.path.join(pdb_dir, protein_name, f\"{protein_name}_protein_{cropped}.pdb\") for protein_name in names]\n",
    "    # names = [os.path.splitext(os.path.basename(p))[0] for p in pdb_paths]\n",
    "    n = len(pdb_paths)\n",
    "\n",
    "    dist_mat = np.zeros((n, n), dtype=float)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            print(f\"Comparing {pdb_paths[i]} vs {pdb_paths[j]}\")\n",
    "            rmsd, tm = run_tmalign(pdb_paths[i], pdb_paths[j])\n",
    "            dist = rmsd  # or (1 - tm), if you prefer to cluster by TM-score\n",
    "            dist_mat[i, j] = dist\n",
    "            dist_mat[j, i] = dist\n",
    "    return names, dist_mat\n",
    "\n",
    "def cluster_structures(pdb_dir, selected_proteins=None, cropped=''):\n",
    "    names, dist_mat = build_structure_distance_matrix(pdb_dir)\n",
    "\n",
    "    dist_condensed = squareform(dist_mat, checks=False)\n",
    "    Z = linkage(dist_condensed, method=\"average\")\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    dendrogram(Z, labels=names, leaf_rotation=90)\n",
    "    plt.title(\"Structure-based clustering (RMSD average linkage)\")\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "pdb_dir = \"/Users/aoxu/projects/DrugDiscovery/PoseBench/data/posebusters_benchmark_set/\"\n",
    "cluster_structures(pdb_dir, selected_proteins=[failed_proteins[0]], cropped='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pocket-Based Clustering (Feature Vectors)\n",
    "Cluster proteins by pocket shape/chemistry rather than the whole structure or sequence\n",
    "\n",
    "Requirements\n",
    "1. A method to extract or compute descriptors for each pocket, e.g. fpocket, SiteMap (Schrödinger), or your own script.\n",
    "2. The pocket descriptor is typically a numeric vector per pocket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pocket-based clustering:\n",
    "1) For each protein's PDB, extract the binding site residues or region.\n",
    "2) Compute a vector of descriptors (volume, area, polarity, etc.).\n",
    "3) Use k-means or hierarchical clustering to group pockets.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "def compute_pocket_features(pdb_path):\n",
    "    \"\"\"\n",
    "    Stub function: you would call a pocket detection tool or your own algorithm.\n",
    "    Return a 1D numpy array of features, e.g. [volume, polar_area, net_charge, ...]\n",
    "    \"\"\"\n",
    "    # TODO: implement real logic\n",
    "    # For demonstration, let's pretend we have random data\n",
    "    import random\n",
    "    feature_vector = np.array([\n",
    "        random.uniform(100, 800),  # pocket volume\n",
    "        random.uniform(0, 300),    # polar surface area\n",
    "        random.uniform(-5, 5),     # net charge\n",
    "        random.uniform(0, 1)       # hydrophobicity index, etc.\n",
    "    ])\n",
    "    return feature_vector\n",
    "\n",
    "def cluster_pockets(pdb_dir, n_clusters=4):\n",
    "    \"\"\"\n",
    "    1) Gather pocket features from each PDB.\n",
    "    2) Run k-means clustering.\n",
    "    \"\"\"\n",
    "    pdb_paths = sorted(glob.glob(os.path.join(pdb_dir, \"*.pdb\")))\n",
    "    names = [os.path.splitext(os.path.basename(p))[0] for p in pdb_paths]\n",
    "\n",
    "    # Compute pocket descriptor for each protein\n",
    "    X = []  # array of feature vectors\n",
    "    for p in pdb_paths:\n",
    "        fv = compute_pocket_features(p)\n",
    "        X.append(fv)\n",
    "    X = np.vstack(X)  # shape: (num_proteins, num_features)\n",
    "\n",
    "    # K-means\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(X)\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    # Print cluster membership\n",
    "    for name, lbl in zip(names, labels):\n",
    "        print(f\"{name} => Cluster {lbl}\")\n",
    "\n",
    "    # Optionally do a 2D plot (if we can do PCA or so)\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    Xp = pca.fit_transform(X)\n",
    "\n",
    "    plt.figure()\n",
    "    colors = cycle([\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\"])\n",
    "    for i, (name, lbl) in enumerate(zip(names, labels)):\n",
    "        c = next(colors)\n",
    "        plt.scatter(Xp[i, 0], Xp[i, 1], color=c, label=f\"Cluster {lbl}\" if i == 0 else \"\")\n",
    "        plt.text(Xp[i, 0]+1, Xp[i, 1], name, fontsize=9)\n",
    "    plt.title(\"Pocket-based clustering (K-means with PCA visualization)\")\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# cluster_pockets(\"path/to/pdb_dir\", n_clusters=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molpal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
